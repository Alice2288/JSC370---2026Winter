---
title: "Lab 06 - Text Mining"
format:
  html:
    embed-resources: true
jupyter: python3
---

# Learning goals

- Use tokenization and n-grams to extract features from text
- Use pandas and plotnine to analyze and visualize text data
- Apply sentence tokenization to analyze text structure
- Apply topic modeling using scikit-learn and see if topics align with medical specialties

# Lab description

For this lab we will be working with the medical record transcriptions from https://www.mtsamples.com/ available at https://github.com/salgadev/medical-nlp.

# Deliverables

1. Questions 1-7 answered, rendered to html and uploaded to Quercus.

2. Add link to your github repo in your html.

https://github.com/Alice2288/JSC370---2026Winter

### Setup packages

You should have the following packages installed: `pandas`, `numpy`, `plotnine`, `nltk`, `wordcloud`, and `scikit-learn`.

```{python}
#| eval: true

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import re

# Plotting with ggplot2 syntax
from plotnine import *

# Text processing
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.util import ngrams
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

# Word cloud
from wordcloud import WordCloud

# Topic modeling
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.decomposition import LatentDirichletAllocation


```

## Read in the Medical Transcriptions

Loading in reference transcription samples from https://www.mtsamples.com/

```{python}
#| eval: true

mt_samples = pd.read_csv("https://raw.githubusercontent.com/salgadev/medical-nlp/master/data/mtsamples.csv")
mt_samples = mt_samples[['description', 'medical_specialty', 'transcription']]

mt_samples.head()
```


## Question 1: What specialties do we have?

We can use `value_counts()` from pandas to figure out how many different medical specialties are in the data. Are these categories related? overlapping? evenly distributed? Make a bar plot.

```{python}
#| eval: true

specialty_counts = mt_samples['medical_specialty'].value_counts().reset_index()  # Hint: count categories
specialty_counts.columns = ['medical_specialty', 'count']

(ggplot(specialty_counts, aes(x='reorder(medical_specialty, count)', y='count'))  # Hint: use the counts dataframe
 + geom_bar(stat='identity', fill='steelblue')
 + coord_flip()
 + labs(x='Medical Specialty', y='Count', title='Distribution of Medical Specialties')
 + theme_minimal()
 + theme(figure_size=(12, 8))
)
```

Summarize the top medical specialties:
The distribution is highly imbalanced, with Surgery dominating the dataset by a large margin.
The next most common categories are Consult – History and Physical and Cardiovascular / Pulmonary.
The labels mix true medical specialties with document types (such as Discharge Summary and SOAP Notes), suggesting overlap and inconsistency.
Overall, the data follows a long-tail pattern, with many categories appearing only rarely.

## Question 2: Tokenize

- Tokenize the words in the `transcription` column
- Count the number of times each token appears
- Visualize the top 20 most frequent words with a bar plot



```{python}
#| eval: true

# Tokenize all transcriptions
def tokenize_text(text):
    if pd.isna(text):
        return []
    return word_tokenize(text.lower())  # Hint: NLTK word tokenizer

all_tokens = []
for text in mt_samples['transcription']:
    all_tokens.extend(tokenize_text(text))

# Count tokens
token_counts = Counter(all_tokens)  # Hint: count token frequencies
top_20 = token_counts.most_common(20)  # Hint: top N entries

# Create dataframe for plotting
top_20_df = pd.DataFrame(top_20, columns=['word', 'count'])  # Hint: the top-20 list

# Bar plot with plotnine
(ggplot(top_20_df, aes(x='reorder(word, count)', y='count'))  # Hint: the top-20 dataframe
 + geom_bar(stat='identity', fill='steelblue')
 + coord_flip()
 + labs(x='Word', y='Frequency', title='Top 20 Most Frequent Words')
 + theme_minimal()
 + theme(figure_size=(10, 6))
)

```


Summarize the top 20 tokens and explain what insights (if any) do we get?
Most of the top tokens are punctuation marks and very common words like “the,” “and,” “of,” and “to.” This is expected for raw text and mainly reflects normal English sentence structure rather than anything medically meaningful.
The word “patient” stands out as one of the few domain-related terms, confirming the clinical nature of the data. However, its presence among mostly stopwords shows that important medical vocabulary is being hidden by very frequent generic words.
The key takeaway is that simple frequency counts on unprocessed text are not very informative. To get useful insights, we would typically remove stopwords and punctuation so that medically relevant terms can become visible.

## Question 3: Stopwords

- Redo Question 2 but remove stopwords
- Use NLTK's stopwords list
- Use regex to remove numbers


```{python}
#| eval: true

# Get English stopwords
stop_words = set(stopwords.words('english'))  # Hint: get stopword list

# Add custom stopwords
custom_stopwords = {'patient', 'also', 'using', 'used'}
stop_words = stop_words.union(custom_stopwords)

# Filter tokens
filtered_tokens = [
    token for token in all_tokens
    if token not in stop_words
    and not re.match(r'^\d+$', token)
    and len(token) > 2  # Remove very short tokens
    and token.isalpha()  # Keep only alphabetic tokens
]

# Count filtered tokens
filtered_counts = Counter(filtered_tokens)
top_20_filtered = filtered_counts.most_common(20)

# Create dataframe for plotting
top_20_filtered_df = pd.DataFrame(top_20_filtered, columns=['word', 'count'])

# Bar plot with plotnine
(ggplot(top_20_filtered_df, aes(x='reorder(word, count)', y='count'))
 + geom_bar(stat='identity', fill='steelblue')
 + coord_flip()
 + labs(x='Word', y='Frequency', title='Top 20 Most Frequent Words (Stopwords Removed)')
 + theme_minimal()
 + theme(figure_size=(10, 6))
)

# Word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(top_20_filtered))
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud (Stopwords Removed)')
plt.show()
```

Summarize: What do we see when you remove stopwords? Does it give us a better idea of what the text is about?
After removing stopwords, the frequent words shift from generic language to content-bearing clinical terms. We now see words like procedure, history, pain, blood, skin, diagnosis, and anesthesia, which are much more indicative of medical narratives.
This gives a clearer picture of what the text is about. Instead of reflecting sentence structure, the dominant tokens now highlight themes related to examinations, treatments, and clinical findings.
Overall, the results are far more informative, showing that preprocessing (especially stopword removal) is essential for meaningful text analysis.

## Question 3b: Custom stopwords

- Import clinical-specific stopwords from the github repository and apply additional filtering. These stopwords are tailored for medical/clinical text and include terms like "patient", "medical", "clinical", etc.

- Try further customizing your stopwords list to include 3-4 additional words of your own that do not appear informative

```{python}
#| eval: true

# Import clinical stopwords from the medical-nlp repository
import urllib.request

clinical_stopwords_url = "https://raw.githubusercontent.com/salgadev/medical-nlp/master/data/clinical-stopwords.txt"
response = urllib.request.urlopen(clinical_stopwords_url)
clinical_stopwords_raw = response.read().decode('utf-8')


clinical_stopwords = set()
for line in clinical_stopwords_raw.split('\n'):
    line = line.strip().lower()
    if line and not line.startswith('#'):
        clinical_stopwords.add(line)

print(f"Number of clinical stopwords: {len(clinical_stopwords)}")
print(f"Sample clinical stopwords: {list(clinical_stopwords)[:20]}")
```


```{python}
#| eval: true

# Combine NLTK stopwords with clinical stopwords
all_stopwords = stop_words.union(clinical_stopwords)

# Add custom stopwords
additional_stopwords = {"left", "right", "normal", "noted"}  # Hint: add 3-4 clinical filler words
all_stopwords = all_stopwords.union(additional_stopwords)  # Hint: set merge

# Filter tokens using combined stopwords
clinical_filtered_tokens = [
    token for token in all_tokens
    if token not in all_stopwords
    and not re.match(r'^\d+$', token)
    and len(token) > 2
    and token.isalpha()
]

# Count filtered tokens
clinical_filtered_counts = Counter(clinical_filtered_tokens)  # Hint: tokens after clinical filtering
top_20_clinical = clinical_filtered_counts.most_common(20)  # Hint: top N

# Create dataframe for plotting
top_20_clinical_df = pd.DataFrame(top_20_clinical, columns=['word', 'count'])  # Hint: top list for plotting
# Bar plot with plotnine

(ggplot(top_20_clinical_df, aes(x='reorder(word, count)', y='count'))  # Hint: clinical top-20 dataframe
 + geom_bar(stat='identity', fill='tomato')
 + coord_flip()
 + labs(x='Word', y='Frequency', title='Top 20 Most Frequent Words (Clinical Stopwords Removed)')
 + theme_minimal()
 + theme(figure_size=(10, 6))
)

```

Summarize: How many clinical stopwords are there? What additional words did you remove? Do the results differ significantly when using clinical stopwords vs. general stopwords?
- There are 806 clinical stopwords in the imported list.
- The additional words you removed were left, right, normal, and noted (on top of the NLTK + clinical stopwords).
- Yes, the results change quite a bit. With only general stopwords removed, the top words still include a lot of clinical “template” language and charting habits. After adding clinical stopwords (and your extra ones), the top tokens shift more toward meaningful medical content like procedures, symptoms, and findings, so the output is noticeably more interpretable.

---

## Question 4: Bigrams

Tokenize the stopword-filtered transcriptions into bigrams and visualize the top 20 most frequent bigrams.

```{python}
#| eval: true

def get_bigrams_from_text(text):
    if pd.isna(text):  # Hint: current text input
        return []
    tokens = word_tokenize(text.lower())  # Hint: lowercase text
    # Filter tokens using clinical stopwords
    tokens = [t for t in tokens if t not in all_stopwords and t.isalpha() and len(t) > 2]  # Hint: minimum length
    return list(nltk.bigrams(tokens))  # Hint: bigram helper


all_bigrams = []
for text in mt_samples['transcription']:
    all_bigrams.extend(get_bigrams_from_text(text))

bigram_counts = Counter(all_bigrams)  # Hint: count bigrams
top_20_bigrams = bigram_counts.most_common(20)

# Create dataframe for bigrams
bigram_df = pd.DataFrame([
    {'bigram': ' '.join(bg), 'count': count}
    for bg, count in top_20_bigrams
])


(ggplot(bigram_df, aes(x='reorder(bigram, count)', y='count'))  # Hint: bigram dataframe
 + geom_bar(stat='identity', fill='steelblue')
 + coord_flip()
 + labs(x='Bigram', y='Frequency', title='Top 20 Bigrams')
 + theme_minimal()
 + theme(figure_size=(10, 6))
)
```

Summarize: do the bigrams make sense

Yes, the bigrams make good sense and look very consistent with clinical documentation.
Many of the most frequent pairs reflect standard medical phrases and report structure, such as “operating room,” “blood pressure,” “preoperative diagnosis,” “physical examination,” and “vital signs.” These are common expressions in clinical and surgical notes.
We also see procedure-related language like “incision made,” “tolerated procedure,” and “recovery room,” which clearly aligns with operative reports. Overall, the bigrams are much more meaningful than single-word frequencies and provide a clearer view of typical clinical concepts and workflows.

## Question 5: Examining bigram words

Using the results from the bigram, pick a word and count the words that appear before and after it, and create a plot of the top 20.

```{python}
#| eval: true

# Pick a word to examine (e.g., 'blood', 'operating', 'diagnosis')
target_word = 'blood'  # Hint: choose a common token

# Find bigrams containing the target word
before_words = []
after_words = []

for bigram, count in bigram_counts.items():
    if bigram[1] == target_word:  # Hint: compare to chosen token
        before_words.extend([bigram[0]] * count)
    if bigram[0] == target_word:  # Hint: compare to chosen token
        after_words.extend([bigram[1]] * count)

# Count words
before_counts = Counter(before_words).most_common(20)  # Hint: top N
after_counts = Counter(after_words).most_common(20)  # Hint: top N

# Create dataframes
before_df = pd.DataFrame(before_counts, columns=['word', 'count'])  # Hint: counts before target
before_df['position'] = 'before'

after_df = pd.DataFrame(after_counts, columns=['word', 'count'])  # Hint: counts after target
after_df['position'] = 'after'
```

```{python}
#| eval: true

# Plot words before
(ggplot(before_df, aes(x='reorder(word, count)', y='count'))  # Hint: dataframe of words before
 + geom_bar(stat='identity', fill='steelblue')
 + coord_flip()
 + labs(x='Word', y='Frequency', title=f'Words Before "{target_word}"')  # Hint: chosen word
 + theme_minimal()
 + theme(figure_size=(7, 6))
)
```


```{python}
#| eval: true

# Plot words after
(ggplot(after_df, aes(x='reorder(word, count)', y='count'))  # Hint: dataframe of words after
 + geom_bar(stat='identity', fill='coral')
 + coord_flip()
 + labs(x='Word', y='Frequency', title=f'Words After "{target_word}"')  # Hint: chosen word
 + theme_minimal()
 + theme(figure_size=(7, 6))
)
```

Briefly summarize the bigram before and after words.

The words appearing before “blood” are largely descriptive or measurement-related, with “estimated” being by far the most frequent. Other common terms like signs, white, red, rate, and pulse suggest clinical observations and vital sign contexts.
The words appearing after “blood” are strongly dominated by pressure and loss, which are standard medical phrases. Additional terms such as cell, sugar, cultures, and transfusion reflect laboratory results and clinical procedures.
Overall, these patterns are clinically meaningful and align well with typical medical documentation, especially phrases like estimated blood loss and blood pressure.

## Question 6: Sentence Tokenization

Tokenize the transcriptions into sentences and analyze sentence-level statistics.

- Count the number of sentences per transcription
- Calculate the average sentence length (in words) per transcription
- Plot the distribution of average sentence length
- Make a boxplot of the average sentence length by specialty

```{python}
#| eval: true

# Tokenize transcriptions into sentences
def get_sentence_stats(text):
    if pd.isna(text):
        return {'num_sentences': 0, 'avg_sentence_length': 0}

    sentences = sent_tokenize(text)  # Hint: sentence tokenizer
    num_sentences = len(sentences)

    if num_sentences == 0:
        return {'num_sentences': 0, 'avg_sentence_length': 0}

    # Calculate average sentence length in words
    sentence_lengths = [len(word_tokenize(sent)) for sent in sentences]
    avg_length = np.mean(sentence_lengths)

    return {'num_sentences': num_sentences, 'avg_sentence_length': avg_length}  # Hint: use computed values

# Apply to all transcriptions
sentence_stats = mt_samples['transcription'].apply(get_sentence_stats)
mt_samples['num_sentences'] = sentence_stats.apply(lambda x: x['num_sentences'])  # Hint: stats series
mt_samples['avg_sentence_length'] = sentence_stats.apply(lambda x: x['avg_sentence_length'])

# Summary statistics
print("Sentence Statistics Summary:")
print(mt_samples[['num_sentences', 'avg_sentence_length']].describe())

# Aggregate sentence stats by specialty for boxplot
specialty_sentence_stats = (
    mt_samples[mt_samples['avg_sentence_length'] > 0]
    .groupby('medical_specialty', as_index=False)['avg_sentence_length']
    .mean()
)
```


```{python}
#| eval: true

(ggplot(mt_samples[mt_samples['avg_sentence_length'] > 0], aes(x='avg_sentence_length'))  # Hint: column name
 + geom_histogram(bins=30, fill='coral', color='white', alpha=0.7)
 + labs(x='Average Sentence Length (words)', y='Count', title='Distribution of Average Sentence Length')
 + theme_minimal()
 + theme(figure_size=(10, 5))
)
```



```{python}
#| eval: true

(ggplot(specialty_sentence_stats, aes(x='reorder(medical_specialty, avg_sentence_length)', y='avg_sentence_length'))  # Hint: aggregated by specialty
 + geom_boxplot(fill='coral', alpha=0.7)
 + coord_flip()
 + labs(x='Medical Specialty', y='Average Sentence Length (words)', title='Average Sentence Length by Medical Specialty')
 + theme_minimal()
 + theme(figure_size=(10, 6))
)
```

Summarize: Do you notice any patterns sentence length across different medical specialties?
The sentence length patterns are fairly consistent across most medical specialties, with average sentence lengths clustering within a relatively narrow range. This suggests that clinical documentation tends to follow similar writing and dictation styles regardless of specialty.
Some specialties show slightly longer sentences, particularly those involving detailed narrative descriptions, while more structured or procedural report types tend to have shorter sentences. However, the differences are modest rather than dramatic.
The distribution plot also shows that most transcriptions fall within a typical sentence-length range, with a small number of longer outliers, which is common in clinical text due to dictation habits and punctuation variability.

---

## Question 7: Topic Models

See if there are any themes in the data by using a topic model (LDA).
- Remove combined NLTK + clinical stopwords
- Use scikit-learn's CountVectorizer to create a document-term matrix
- Use LatentDirichletAllocation for topic modeling
- Try different k (n_components) values (try 3 and 5)
- Create a visualization of the topics

```{python}
#| eval: true

# Prepare text data
texts = mt_samples['transcription'].dropna().tolist()

vectorizer = CountVectorizer(
    max_df=0.95,  # Ignore terms that appear in >95% of documents (filters common words)
    min_df=2,     # Ignore terms that appear in <2 documents (ignores very rare words)
    stop_words=list(all_stopwords),
    max_features=1000
)
dtm = vectorizer.fit_transform(texts)
```

```{python}
#| eval: true

n_topics =  5 # Hint: number of topics
lda = LatentDirichletAllocation(
    n_components=n_topics,  # Hint: use topic count
    random_state=42,
    max_iter=10
)
lda.fit(dtm)

feature_names = vectorizer.get_feature_names_out()

# Extract top words for each topic into a dataframe
def get_topic_df(model, feature_names, n_top_words=10):
    rows = []
    for topic_idx, topic in enumerate(model.components_):
        top_indices = topic.argsort()[:-n_top_words - 1:-1]
        for rank, idx in enumerate(top_indices):
            rows.append({
                'topic': f'Topic {topic_idx + 1}',
                'word': feature_names[idx],
                'weight': topic[idx],
                'rank': rank
            })
    return pd.DataFrame(rows)

topic_df = get_topic_df(lda, feature_names, 10)  # Hint: model, vocab list, top words

# Display top words per topic
for topic in topic_df['topic'].unique():
    words = topic_df[topic_df['topic'] == topic]['word'].tolist()
    print(f"{topic}: {', '.join(words)}")

# Visualize topics with faceted plot
(ggplot(topic_df, aes(x='reorder(word, weight)', y='weight'))  # Hint: topic dataframe
 + geom_bar(stat='identity', fill='steelblue')
 + coord_flip()
 + facet_wrap('~topic', scales='free_y', ncol=3)
 + labs(x='Word', y='Weight', title='Top Words per Topic (LDA)')
 + theme_minimal()
 + theme(figure_size=(14, 8), strip_text=element_text(size=10))
)
```

Summarize: is it clearer when there are 3 or 5 topics?

Using 5 topics produces clearer and more interpretable themes than using 3 topics.
With 5 topics, the model separates the corpus into coherent clinical groupings, such as cervical spine complaints, procedural language, cardiovascular interventions, orthopedic injuries, and general clinical history. The word clusters align well with recognizable medical contexts.
With only 3 topics, these domains tend to blend together, resulting in broader and less distinct themes.
Overall, 5 topics provide more meaningful and easier-to-interpret structure.

- Now do a cross tab of the 5 topics and the medical specialties.

```{python}
#| eval: true

# Assign documents to topics and compare with actual specialties
doc_topic_dist = lda.transform(dtm)
dominant_topics = doc_topic_dist.argmax(axis=1)

# Add to dataframe
mt_samples_with_topics = mt_samples.dropna(subset=['transcription']).copy()
mt_samples_with_topics['dominant_topic'] = [f'Topic {t+1}' for t in dominant_topics]

# Cross-tabulation of topics vs specialties (top 5 specialties)
top_5_specialties = mt_samples_with_topics['medical_specialty'].value_counts().head(5).index.tolist()  # Hint: number of specialties
cross_tab = pd.crosstab(
    mt_samples_with_topics[mt_samples_with_topics['medical_specialty'].isin(top_5_specialties)]['medical_specialty'],
    mt_samples_with_topics[mt_samples_with_topics['medical_specialty'].isin(top_5_specialties)]['dominant_topic']
)
print("\nCross-tabulation of Topics vs Top 5 Specialties:")
print(cross_tab)
```

Summarize: What themes emerge from the topic modeling? Do the topics align with the medical specialties?

The topic model reveals several coherent clinical themes. The dominant word groups suggest topics related to cervical spine complaints, procedural or surgical language, cardiovascular or vascular interventions, orthopedic injuries, and general clinical history or documentation.
The cross-tabulation indicates partial alignment between topics and medical specialties. Some specialties concentrate strongly within particular topics. For example, Surgery is heavily associated with one topic, which is consistent with the procedure-oriented vocabulary. Orthopedic documents cluster mainly in another topic, matching musculoskeletal terminology. Cardiovascular / Pulmonary records also show higher counts in a topic characterized by vascular or cardiac terms.
However, the alignment is not perfect. Specialties such as Radiology and Consult – History and Physical are distributed across multiple topics, suggesting that their language overlaps with several clinical themes rather than mapping cleanly to a single topic.
Overall, the topics capture meaningful clinical patterns, and while there is noticeable correspondence with specialties, the model reflects shared medical language across domains rather than strict one-to-one separation.
